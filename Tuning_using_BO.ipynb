{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4382703a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:00.158993Z",
     "start_time": "2023-03-09T09:06:56.302860Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import time\n",
    "xformatter = mdates.DateFormatter('%H:%M')  # for time axis plots\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('seaborn-whitegrid')\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from pickle import load,dump\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Bidirectional, BatchNormalization, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.backend import clear_session\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76afd0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:00.174313Z",
     "start_time": "2023-03-09T09:07:00.160804Z"
    }
   },
   "outputs": [],
   "source": [
    "FORMAT_TIME='%Y-%m-%d %H:%M:%S'\n",
    "START_TIME_DAY = time(5,0,0)\n",
    "END_TIME_DAY = time(18,30,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e233da03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:00.190397Z",
     "start_time": "2023-03-09T09:07:00.177313Z"
    }
   },
   "outputs": [],
   "source": [
    "TIME_1_STEP = 15 # minute\n",
    "step_lag_1_day = 24*60//TIME_1_STEP\n",
    "steps_2hours = 60*2//TIME_1_STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "304d8669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:00.206164Z",
     "start_time": "2023-03-09T09:07:00.192315Z"
    }
   },
   "outputs": [],
   "source": [
    "activation_list = ['linear','relu', 'tanh','sigmoid']\n",
    "optimizer_list = ['adam', 'rmsprop','sgd','Adamax']\n",
    "range_neurons = [8,100]\n",
    "selectors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e096704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:00.222332Z",
     "start_time": "2023-03-09T09:07:00.207038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nhap du lieu train data\n",
    "def import_train_data(path_file_train):\n",
    "    df = pd.read_csv(path_file_train)\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp']\n",
    "                                      )\n",
    "    df = df.set_index('TimeStamp')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202d62c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:00.238081Z",
     "start_time": "2023-03-09T09:07:00.224278Z"
    }
   },
   "outputs": [],
   "source": [
    "def resample_df(df, resample_time, time_col='TimeStamp'):\n",
    "    \"\"\"\n",
    "    resample_time: `minute`\n",
    "    \"\"\"\n",
    "    resample_df = df.copy()\n",
    "    if resample_time >= 30:\n",
    "        resample_df = resample_df.set_index(\n",
    "            resample_df[time_col] - to_offset(str(resample_time//2)+\"min\"))\n",
    "    resample_df = resample_df.resample(str(resample_time)+'min', label='right').mean()\n",
    "    return resample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524a46c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.289Z"
    }
   },
   "outputs": [],
   "source": [
    "all_plant = import_train_data('./LN2_training.csv')\n",
    "all_plant = resample_df(all_plant, resample_time = 15, time_col='TimeStamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709fa32",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split train, val data theo ti le 8/2\n",
    "def train_valid_split(df, split_ratio=[0.8, 0.2]):\n",
    "    train_ratio, valid_ratio = split_ratio\n",
    "    assert train_ratio + valid_ratio  == 1.0\n",
    "    n_df = len(df)\n",
    "    # Train / Validation  Split\n",
    "    train_split = int(n_df * train_ratio)\n",
    "    valid_split = int(n_df * (train_ratio + valid_ratio))\n",
    "\n",
    "    train = df[:train_split]\n",
    "    val = df[train_split:valid_split]\n",
    "\n",
    "    print(f'Train set: {len(train)} ')\n",
    "    print(f'Validation set: {len(val)} ')\n",
    "\n",
    "    return train, val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8e056",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.291Z"
    }
   },
   "outputs": [],
   "source": [
    "def num_step_1hour(df):\n",
    "    \"\"\"\n",
    "    Get number step of 1 hours\n",
    "    \"\"\"\n",
    "    step_hours = None\n",
    "    if type(df.index) == pd.core.indexes.datetimes.DatetimeIndex:\n",
    "        time_1step = int((df.index[1] - df.index[0]) /\n",
    "                         np.timedelta64(1, 'm'))  # minute\n",
    "        step_hours = 60 // time_1step\n",
    "    return step_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7685aa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.292Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_data_supervised(dt, num_pre_around=5, num_day_pre=3):\n",
    "    step_lag_1_day = num_step_1hour(dt)*24\n",
    "    dt_lag = pd.DataFrame()\n",
    "    for col in dt.columns:\n",
    "        for day_pre in range(num_pre_around+1):\n",
    "            if day_pre == 0:\n",
    "                dt_lag[col+'(t)'] = dt[col]\n",
    "            else:\n",
    "                dt_lag[col+'(t-'+str(day_pre)+')'] = dt[col].shift(day_pre)\n",
    "        for day_pre in range(1, num_day_pre):\n",
    "            step_lag = step_lag_1_day*day_pre\n",
    "            for lag in range(num_pre_around+1):\n",
    "                dt_lag[col+'(t-'+str(step_lag+lag) +\n",
    "                       ')'] = dt[col].shift(step_lag+lag)\n",
    "                dt_lag[col+'(t-'+str(step_lag-lag) +\n",
    "                       ')'] = dt[col].shift(step_lag-lag)\n",
    "    dt_lag = dt_lag.dropna()\n",
    "    dt_lag['hour'] = dt_lag.index.hour\n",
    "    dt_lag['day'] = dt_lag.index.day\n",
    "    dt_lag['day_of_week'] = dt_lag.index.dayofweek\n",
    "    dt_lag['month'] = dt_lag.index.month\n",
    "    dt_lag['day_of_year'] = dt_lag.index.dayofyear\n",
    "    return dt_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af49c3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.293Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_Kbest(train,score_f):\n",
    "    X_select = train[train.columns[1:]]\n",
    "    y_select = train['TotW(t)']\n",
    "    bestfeatures = SelectKBest(score_func=score_f, k='all')\n",
    "    fit = bestfeatures.fit(X_select,y_select)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X_select.columns)\n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  \n",
    "    featureScores = featureScores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "    return featureScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7d205",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.295Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_model(train, val, bo_result):\n",
    "    train_X, train_y = train.values[:, 1:], train.values[:, :1]\n",
    "    train_X = train_X.reshape(train_X.shape[0], 1, train_X.shape[1])\n",
    "\n",
    "    val_X, val_y = val.values[:, 1:], val.values[:, :1]\n",
    "    val_X = val_X.reshape(val_X.shape[0], 1, val_X.shape[1])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Bidirectional(LSTM(bo_result['num_feature'],\n",
    "             activation=bo_result['activations'],\n",
    "             input_shape=(train_X.shape[1], train_X.shape[2])),merge_mode= 'ave'))   \n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer=bo_result['optimizers'],\n",
    "                  metrics=['mse', 'mae', 'cosine_proximity'])\n",
    "    # fit network\n",
    "    history = model.fit(train_X,\n",
    "                        train_y,\n",
    "                        epochs=100,\n",
    "                        batch_size=50,\n",
    "                        validation_data=(val_X, val_y),\n",
    "                        verbose=1,\n",
    "                        shuffle=False,\n",
    "                        callbacks=EarlyStopping(monitor='val_loss',\n",
    "                                                patience=15,\n",
    "                                                restore_best_weights=True))\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    fig.suptitle('Loss', y=0.93)\n",
    "    ax.plot(history.history['mae'], label='train')\n",
    "    ax.plot(history.history['val_mae'], label='val')\n",
    "    ax.set_title('mae')\n",
    "    ax.legend(loc='upper right')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f26455",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.296Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_or_create_path(path):\n",
    "    if os.path.isdir(path) is False:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c129e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.297Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_func(train, val, path_scale):\n",
    "    get_or_create_path(path_scale)\n",
    "    train_scale_df = pd.DataFrame(index=train.index)\n",
    "    val_scale_df = pd.DataFrame(index=val.index)\n",
    "    \n",
    "    for col in train.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        train_scale_df[col] = scaler.fit_transform(train[col].values.reshape(-1,1))[:,0]\n",
    "        val_scale_df[col] = scaler.transform(val[col].values.reshape(-1,1))[:,0]\n",
    "        pickle.dump(scaler, open(path_scale + col+'.pkl','ab+'))\n",
    "    return train_scale_df,val_scale_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de332f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.297Z"
    }
   },
   "outputs": [],
   "source": [
    "def BO_result(bo_model):\n",
    "    best_neurons = (round(bo_model.max['params']['neurons']))\n",
    "    best_activation = (round(bo_model.max['params']['activation']))\n",
    "    best_optimizer = (round(bo_model.max['params']['optimizer']))\n",
    "    return {\n",
    "        'activations': activation_list[best_activation],\n",
    "        'optimizers': optimizer_list[best_optimizer],\n",
    "        'neurons': best_neurons,\n",
    "        'num_feature': (round(bo_model.max['params']['number_features']))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9dc164",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.298Z"
    }
   },
   "outputs": [],
   "source": [
    "#def tong\n",
    "def LSTM_BO(df, path_model, path_scale, path_feature):\n",
    "    #Hàm evaluate\n",
    "    def evaluate(neurons, activation, optimizer, number_features):\n",
    "        neurons = round(neurons)\n",
    "        activation = round(activation)\n",
    "        optimizer = round(optimizer)\n",
    "        number_features = round(number_features)\n",
    "        train_X_ = train_X.copy()\n",
    "        val_X_ = val_X.copy()\n",
    "        train_y_ = train_y.copy()\n",
    "        val_y_ = val_y.copy()\n",
    "        print(neurons, activation, optimizer, number_features)\n",
    "        selector = SelectKBest(score_func=f_regression, k=number_features)\n",
    "        train_X_ = train_X_.reshape(train_X_.shape[0], train_X_.shape[2])\n",
    "        val_X_ = val_X_.reshape(val_X_.shape[0], val_X_.shape[2])\n",
    "        train_X_ = selector.fit_transform(train_X_, train_y_)\n",
    "        val_X_ = selector.transform(val_X_)\n",
    "        train_X_ = train_X_.reshape(train_X_.shape[0],1,train_X_.shape[1])\n",
    "        val_X_ = val_X_.reshape(val_X_.shape[0],1,val_X_.shape[1])\n",
    "        print('\\nNumber of neurons: ', neurons,\n",
    "              ', activation function: ', activation_list[activation],\n",
    "              ', optimizer function: ', optimizer_list[optimizer],\n",
    "              ', features: ', number_features)\n",
    "        clear_session()\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Bidirectional(LSTM(neurons, activation=activation_list[activation], \n",
    "                                     input_shape=(train_X_.shape[1], train_X_.shape[2])),merge_mode= 'ave'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mae', optimizer=optimizer_list[optimizer])\n",
    "        history = model.fit(train_X_, train_y_,validation_data=(val_X_, val_y_),callbacks = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True), \n",
    "            epochs=100, batch_size=50, verbose=0,shuffle=False)\n",
    "        print('val_loss: ', min(history.history['val_loss']))\n",
    "        return -min(history.history['val_loss'])\n",
    "        \n",
    "    \n",
    "    train_solar, val_solar = train_valid_split(df,split_ratio=[0.8, 0.2]) # split train/val\n",
    "    train_scale, val_scale = scale_func(train_solar, val_solar, path_scale)\n",
    "\n",
    "    train_scaler_lag = make_data_supervised(train_scale)\n",
    "    val_scaler_lag = make_data_supervised(val_scale)\n",
    "    \n",
    "    col_analysis = list(train_scaler_lag)\n",
    "    train_solar = train_scaler_lag[col_analysis].copy()\n",
    "    val_solar = val_scaler_lag[col_analysis].copy()\n",
    "    \n",
    "    featureScores = select_Kbest(train_solar[col_analysis],f_regression)\n",
    "    \n",
    "    train_X, train_y= train_solar.values[:, 1:],train_solar.values[:, :1]\n",
    "    train_X = train_X.reshape(train_X.shape[0], 1, train_X.shape[1])\n",
    "    val_X, val_y= val_solar.values[:, 1:],val_solar.values[:, :1]\n",
    "    val_X = val_X.reshape(val_X.shape[0], 1, val_X.shape[1])\n",
    "    \n",
    "    best_activation, best_optimizer, best_neurons, selectors = [], [], [], []\n",
    "    pbounds = {'neurons' : (8,100),\n",
    "               'activation': (0,3),\n",
    "               'optimizer': (0,3), \n",
    "               'number_features': (1, train_X.shape[2])}\n",
    "    bo_optimize = BayesianOptimization(f=evaluate,\n",
    "                                    pbounds=pbounds,\n",
    "                                    random_state=3)\n",
    "    bo_optimize.maximize(init_points=10 ,n_iter=25)\n",
    "    print(bo_optimize.max)\n",
    "    \n",
    "    bo_result = BO_result(bo_optimize)\n",
    "    best_feature = list(featureScores['Specs'][:round(bo_optimize.max['params']['number_features'])])\n",
    "    pickle.dump(best_feature, open(path_feature + 'best_feature.pkl','wb'))\n",
    "    \n",
    "    train_solar = train_scaler_lag[['TotW(t)']+best_feature]\n",
    "    val_solar = val_scaler_lag[['TotW(t)']+best_feature]\n",
    "    \n",
    "    model = make_model(train_solar,val_solar,bo_result)\n",
    "    model.save(path_model)\n",
    "    \n",
    "    return bo_optimize, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1709d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:06:56.300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bo_optimize, model = LSTM_BO(all_plant,'./LN2/4H.h5','./LN2/','./LN2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfed318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
