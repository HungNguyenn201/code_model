{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import time\n",
    "xformatter = mdates.DateFormatter('%H:%M')  # for time axis plots\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "style.use('seaborn-whitegrid')\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "\n",
    "\n",
    "\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from pickle import load,dump\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "from keras.backend import clear_session\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORMAT_TIME='%Y-%m-%d %H:%M:%S'\n",
    "START_TIME_DAY = time(5,0,0)\n",
    "END_TIME_DAY = time(18,30,0)\n",
    "TIME_1_STEP = 15 # minute\n",
    "step_lag_1_day = 24*60//TIME_1_STEP\n",
    "steps_2hours = 60*2//TIME_1_STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_list = ['linear','relu', 'tanh','sigmoid']\n",
    "optimizer_list = [Adam, RMSprop, SGD, Adamax]\n",
    "range_neurons_lstm = [8,100]\n",
    "# range_lr = [1, 1000]\n",
    "number_hidden_layers = [1,5]\n",
    "loss_list = ['binary_crossentropy', 'mse', 'mae']\n",
    "selectors = []\n",
    "algorithm_param = {\n",
    "    'max_num_iteration': 5,\n",
    "    'population_size': 5,\n",
    "    'mutation_probability': 0.1,\n",
    "    'elit_ratio': 0.2,\n",
    "    'crossover_probability': 0.5,\n",
    "    'parents_portion': 0,\n",
    "    'crossover_type': 'uniform',\n",
    "    'max_iteration_without_improv': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhap du lieu train data\n",
    "def import_train_data(path_file_train):\n",
    "    df = pd.read_csv(path_file_train)\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp']\n",
    "                                      )\n",
    "    df = df.set_index('TimeStamp')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_df(df, resample_time, time_col='TimeStamp'):\n",
    "    \"\"\"\n",
    "    resample_time: `minute`\n",
    "    \"\"\"\n",
    "    resample_df = df.copy()\n",
    "    if resample_time >= 30:\n",
    "        resample_df = resample_df.set_index(\n",
    "            resample_df[time_col] - to_offset(str(resample_time//2)+\"min\"))\n",
    "    resample_df = resample_df.resample(str(resample_time)+'min', label='right').mean()\n",
    "    return resample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plant = import_train_data('./LN2_training.csv')\n",
    "all_plant = resample_df(all_plant, resample_time = 15, time_col='TimeStamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train, val data theo ti le 8/2\n",
    "def train_valid_split(df, split_ratio=[0.8, 0.2]):\n",
    "    train_ratio, valid_ratio = split_ratio\n",
    "    assert train_ratio + valid_ratio  == 1.0\n",
    "    n_df = len(df)\n",
    "    # Train / Validation  Split\n",
    "    train_split = int(n_df * train_ratio)\n",
    "    valid_split = int(n_df * (train_ratio + valid_ratio))\n",
    "\n",
    "    train = df[:train_split]\n",
    "    val = df[train_split:valid_split]\n",
    "\n",
    "    print(f'Train set: {len(train)} ')\n",
    "    print(f'Validation set: {len(val)} ')\n",
    "\n",
    "    return train, val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_step_1hour(df):\n",
    "    \"\"\"\n",
    "    Get number step of 1 hours\n",
    "    \"\"\"\n",
    "    step_hours = None\n",
    "    if type(df.index) == pd.core.indexes.datetimes.DatetimeIndex:\n",
    "        time_1step = int((df.index[1] - df.index[0]) /\n",
    "                         np.timedelta64(1, 'm'))  # minute\n",
    "        step_hours = 60 // time_1step\n",
    "    return step_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_supervised(dt, num_pre_around=5, num_day_pre=3):\n",
    "    step_lag_1_day = num_step_1hour(dt)*24\n",
    "    dt_lag = pd.DataFrame()\n",
    "    for col in dt.columns:\n",
    "        for day_pre in range(num_pre_around+1):\n",
    "            if day_pre == 0:\n",
    "                dt_lag[col+'(t)'] = dt[col]\n",
    "            else:\n",
    "                dt_lag[col+'(t-'+str(day_pre)+')'] = dt[col].shift(day_pre)\n",
    "        for day_pre in range(1, num_day_pre):\n",
    "            step_lag = step_lag_1_day*day_pre\n",
    "            for lag in range(num_pre_around+1):\n",
    "                dt_lag[col+'(t-'+str(step_lag+lag) +\n",
    "                       ')'] = dt[col].shift(step_lag+lag)\n",
    "                dt_lag[col+'(t-'+str(step_lag-lag) +\n",
    "                       ')'] = dt[col].shift(step_lag-lag)\n",
    "    dt_lag = dt_lag.dropna()\n",
    "    dt_lag['hour'] = dt_lag.index.hour\n",
    "    dt_lag['day'] = dt_lag.index.day\n",
    "    dt_lag['day_of_week'] = dt_lag.index.dayofweek\n",
    "    dt_lag['month'] = dt_lag.index.month\n",
    "    dt_lag['day_of_year'] = dt_lag.index.dayofyear\n",
    "    return dt_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_Kbest(train,score_f):\n",
    "    X_select = train[train.columns[1:]]\n",
    "    y_select = train['TotW(t)']\n",
    "    bestfeatures = SelectKBest(score_func=score_f, k='all')\n",
    "    fit = bestfeatures.fit(X_select,y_select)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X_select.columns)\n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  \n",
    "    featureScores = featureScores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "    return featureScores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_path(path):\n",
    "    if os.path.isdir(path) is False:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_func(train, val, path_scale):\n",
    "    get_or_create_path(path_scale)\n",
    "    train_scale_df = pd.DataFrame(index=train.index)\n",
    "    val_scale_df = pd.DataFrame(index=val.index)\n",
    "    \n",
    "    for col in train.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        train_scale_df[col] = scaler.fit_transform(train[col].values.reshape(-1,1))[:,0]\n",
    "        val_scale_df[col] = scaler.transform(val[col].values.reshape(-1,1))[:,0]\n",
    "        pickle.dump(scaler, open(path_scale + col+'.pkl','ab+'))\n",
    "    return train_scale_df,val_scale_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_path(path):\n",
    "    if os.path.isdir(path) is False:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_func(train, val, path_scale):\n",
    "    get_or_create_path(path_scale)\n",
    "    train_scale_df = pd.DataFrame(index=train.index)\n",
    "    val_scale_df = pd.DataFrame(index=val.index)\n",
    "    \n",
    "    for col in train.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        train_scale_df[col] = scaler.fit_transform(train[col].values.reshape(-1,1))[:,0]\n",
    "        val_scale_df[col] = scaler.transform(val[col].values.reshape(-1,1))[:,0]\n",
    "        pickle.dump(scaler, open(path_scale + col+'.pkl','ab+'))\n",
    "    return train_scale_df,val_scale_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 39782 \n",
      "Validation set: 9946 \n"
     ]
    }
   ],
   "source": [
    "train_solar, val_solar = train_valid_split(all_plant,split_ratio=[0.8, 0.2]) # split train/val\n",
    "train_scale, val_scale = scale_func(train_solar, val_solar, './LN2/')\n",
    "\n",
    "train_scaler_lag = make_data_supervised(train_scale)\n",
    "val_scaler_lag = make_data_supervised(val_scale)\n",
    "\n",
    "col_analysis = list(train_scaler_lag)\n",
    "train_solar = train_scaler_lag[col_analysis].copy()\n",
    "val_solar = val_scaler_lag[col_analysis].copy()\n",
    "\n",
    "featureScores = select_Kbest(train_solar[col_analysis],f_regression)\n",
    "# featureScores.to_csv('./LN2_4H_kbest.csv')\n",
    "\n",
    "train_X, train_y= train_solar.values[:, 1:],train_solar.values[:, :1]\n",
    "train_X = train_X.reshape(train_X.shape[0], 1, train_X.shape[1])\n",
    "val_X, val_y= val_solar.values[:, 1:],val_solar.values[:, :1]\n",
    "val_X = val_X.reshape(val_X.shape[0], 1, val_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gene):\n",
    "    g = [int(i) for i in gene]\n",
    "    train_X_ = train_X.copy()\n",
    "    val_X_ = val_X.copy()\n",
    "    train_y_ = train_y.copy()\n",
    "    val_y_ = val_y.copy()\n",
    "    selector = SelectKBest(score_func=f_regression, k=g[5])\n",
    "    train_X_ = train_X_.reshape(train_X_.shape[0], train_X_.shape[2])\n",
    "    val_X_ = val_X_.reshape(val_X_.shape[0], val_X_.shape[2])\n",
    "    train_X_ = selector.fit_transform(train_X_, train_y_)\n",
    "    val_X_ = selector.transform(val_X_)\n",
    "    train_X_ = train_X_.reshape(train_X_.shape[0],1,train_X_.shape[1])\n",
    "    val_X_ = val_X_.reshape(val_X_.shape[0],1,val_X_.shape[1])\n",
    "\n",
    "    neurons = g[0]\n",
    "    activation = activation_list[g[1]]\n",
    "    optimizer = optimizer_list[g[2]]\n",
    "    hidden_layers = g[3]\n",
    "    # learning_rate = g[4]\n",
    "    loss_function = loss_list[g[4]]\n",
    "    # learning_rate_flt =  learning_rate / 10000\n",
    "    \n",
    "    print('\\nNumber of neurons: ', neurons,\n",
    "        ', activation function: ', activation,\n",
    "        ', optimizer function: ', optimizer,\n",
    "        ', hidden_layers: ', hidden_layers,\n",
    "        # ', learning_rate: ', learning_rate_flt,\n",
    "        ', loss_function: ', loss_function,\n",
    "        ', features: ', g[5])\n",
    "    \n",
    "    clear_session()\n",
    "    model = Sequential()\n",
    "    for i in range(hidden_layers):\n",
    "        if i == 0: \n",
    "            model.add(Bidirectional(LSTM(neurons, activation=activation, \n",
    "                                     input_shape=(train_X_.shape[1], train_X_.shape[2]),\n",
    "                                     return_sequences=True)))\n",
    "        else:\n",
    "            model.add(Bidirectional(LSTM(neurons, activation=activation, return_sequences=True)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=loss_function, optimizer=optimizer(learning_rate=0.03))\n",
    "\n",
    "    history = model.fit(train_X_, train_y_,validation_data=(val_X_, val_y_),\n",
    "                callbacks = EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=15,\n",
    "                restore_best_weights=True), \n",
    "                epochs=100, batch_size=50, verbose=0,shuffle=False)\n",
    "    print('val_loss: ', min(history.history['val_loss']))\n",
    "    return min(history.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "varbound = np.array([range_neurons_lstm, [0, 3], [0, 3],\n",
    "                     number_hidden_layers, [0, 2] ,[1, train_X.shape[2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of neurons:  8 , activation function:  relu , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  3 , loss_function:  mae , features:  76\n",
      "val_loss:  0.012235970236361027\n",
      "\n",
      "Number of neurons:  39 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  88\n",
      "val_loss:  0.00277468329295516\n",
      "\n",
      "Number of neurons:  72 , activation function:  relu , optimizer function:  <class 'keras.optimizer_v2.adamax.Adamax'> , hidden_layers:  5 , loss_function:  mae , features:  48\n",
      "val_loss:  0.011399464681744576\n",
      "\n",
      "Number of neurons:  64 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.gradient_descent.SGD'> , hidden_layers:  5 , loss_function:  binary_crossentropy , features:  32\n",
      "val_loss:  12.390419960021973\n",
      "\n",
      "Number of neurons:  39 , activation function:  tanh , optimizer function:  <class 'keras.optimizer_v2.rmsprop.RMSprop'> , hidden_layers:  5 , loss_function:  mae , features:  43\n",
      "val_loss:  0.023179905489087105\n",
      "||||||||||________________________________________ 20.0% GA is running...\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  4\n",
      "val_loss:  0.0005116187385283411\n",
      "\n",
      "Number of neurons:  39 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mae , features:  88\n",
      "val_loss:  0.03908104449510574\n",
      "\n",
      "Number of neurons:  39 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  88\n",
      "val_loss:  0.000808579265139997\n",
      "\n",
      "Number of neurons:  39 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  88\n",
      "val_loss:  0.0008048218442127109\n",
      "||||||||||||||||||||______________________________ 40.0% GA is running...\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  30\n",
      "val_loss:  0.0005451107281260192\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  4\n",
      "val_loss:  0.0005260903853923082\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  4 , loss_function:  mse , features:  4\n",
      "val_loss:  0.000591636635363102\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  4\n",
      "val_loss:  0.0005049860919825733\n",
      "||||||||||||||||||||||||||||||____________________ 60.0% GA is running...\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  4\n",
      "val_loss:  0.0005126240430399776\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mae , features:  4\n",
      "val_loss:  0.010830188170075417\n",
      "\n",
      "Number of neurons:  97 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  4\n",
      "val_loss:  0.0005051628686487675\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mae , features:  4\n",
      "val_loss:  0.010876038111746311\n",
      "||||||||||||||||||||||||||||||||||||||||__________ 80.0% GA is running...\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  4\n",
      "val_loss:  0.0005111343925818801\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  4\n",
      "val_loss:  0.0005097807152196765\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mae , features:  4\n",
      "val_loss:  0.0116001907736063\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  4\n",
      "val_loss:  0.000520245754159987\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||| 100.0% GA is running...\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mse , features:  4\n",
      "val_loss:  0.0005153854726813734\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  3 , loss_function:  mse , features:  4\n",
      "val_loss:  0.0004978100769221783\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  2 , loss_function:  mse , features:  4\n",
      "val_loss:  0.0005180328153073788\n",
      "\n",
      "Number of neurons:  84 , activation function:  linear , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , hidden_layers:  1 , loss_function:  mae , features:  4\n",
      "val_loss:  0.01124642975628376\n",
      " The best solution found:                                                                           \n",
      " [84.  0.  0.  3.  1.  4.]\n",
      "\n",
      " Objective function:\n",
      " 0.0004978100769221783\n"
     ]
    }
   ],
   "source": [
    "ga_model = ga(function=evaluate,\n",
    "                dimension=6,\n",
    "                variable_type='int',\n",
    "                function_timeout=10000,\n",
    "                variable_boundaries=varbound,\n",
    "                convergence_curve=False,\n",
    "                algorithm_parameters=algorithm_param)\n",
    "ga_model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_result(ga_model):\n",
    "    best_neurons = (int(ga_model.best_variable[0]))\n",
    "    best_activation = (int(ga_model.best_variable[1]))\n",
    "    best_optimizer = (int(ga_model.best_variable[2]))\n",
    "    best_hidden_layers = (int(ga_model.best_variable[3]))\n",
    "    # best_learning_rate = ((int(ga_model.best_variable[4]))/10000)\n",
    "    best_loss_function = (int(ga_model.best_variable[4]))\n",
    "    return {\n",
    "        'activations': activation_list[best_activation],\n",
    "        'optimizers': optimizer_list[best_optimizer],\n",
    "        'neurons': best_neurons,\n",
    "        'hidden_layers': best_hidden_layers,\n",
    "        # 'learning_rate': best_learning_rate,\n",
    "        'loss_function': loss_list[best_loss_function],\n",
    "        'num_feature': int(ga_model.best_variable[5])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_result = GA_result(ga_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(train, val, ga_result):\n",
    "    train_X, train_y = train.values[:, 1:], train.values[:, :1]\n",
    "    train_X = train_X.reshape(train_X.shape[0], 1, train_X.shape[1])\n",
    "    \n",
    "    val_X, val_y = val.values[:, 1:], val.values[:, :1]\n",
    "    val_X = val_X.reshape(val_X.shape[0], 1, val_X.shape[1])\n",
    "\n",
    "    model = Sequential()\n",
    "    for i in range(ga_result['hidden_layers']):\n",
    "        if i == 0:\n",
    "            model.add(\n",
    "            Bidirectional(LSTM(ga_result['neurons'],\n",
    "                activation=ga_result['activations'], input_shape=(train_X.shape[1],train_X.shape[2]),\n",
    "                return_sequences=True)))\n",
    "        else:\n",
    "            \n",
    "            model.add(Bidirectional(LSTM(ga_result['neurons'],\n",
    "                                        activation=ga_result['activations'], \n",
    "                                        return_sequences=True)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))   \n",
    "    # model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=ga_result['loss_function'],\n",
    "                  optimizer=ga_result['optimizers'](learning_rate = 0.03),\n",
    "                  metrics=['mse', 'mae', 'cosine_proximity'])\n",
    "    # fit network\n",
    "    history = model.fit(train_X,\n",
    "                        train_y,\n",
    "                        epochs=100,\n",
    "                        batch_size=50,\n",
    "                        validation_data=(val_X, val_y),\n",
    "                        verbose=1,\n",
    "                        shuffle=False,\n",
    "                        callbacks=EarlyStopping(monitor='val_loss',\n",
    "                                                patience=15,\n",
    "                                                restore_best_weights=True))\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    fig.suptitle('Loss', y=0.93)\n",
    "    ax.plot(history.history['mae'], label='train')\n",
    "    ax.plot(history.history['val_mae'], label='val')\n",
    "    ax.set_title('mae')\n",
    "    ax.legend(loc='upper right')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature = list(featureScores['Specs'][:ga_result['num_feature']])\n",
    "\n",
    "train_solar = train_scaler_lag[['TotW(t)']+best_feature]\n",
    "val_solar = val_scaler_lag[['TotW(t)']+best_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "792/792 [==============================] - 11s 7ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0361 - cosine_proximity: 0.5225 - val_loss: 5.5496e-04 - val_mse: 5.5496e-04 - val_mae: 0.0125 - val_cosine_proximity: 0.5264: 0.0562 - cosine_proximi - ETA: 2s - loss: 0.0105 -  - ETA: 1s - loss: 0.0070 \n",
      "Epoch 2/100\n",
      "792/792 [==============================] - 5s 6ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0224 - cosine_proximity: 0.5424 - val_loss: 6.4074e-04 - val_mse: 6.4074e-04 - val_mae: 0.0182 - val_cosine_proximity: 0.5274\n",
      "Epoch 3/100\n",
      "792/792 [==============================] - 5s 7ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0353 - cosine_proximity: 0.5250 - val_loss: 7.4046e-04 - val_mse: 7.4046e-04 - val_mae: 0.0157 - val_cosine_proximity: 0.5135\n",
      "Epoch 4/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0209 - cosine_proximity: 0.5320 - val_loss: 5.1352e-04 - val_mse: 5.1352e-04 - val_mae: 0.0116 - val_cosine_proximity: 0.5274\n",
      "Epoch 5/100\n",
      "792/792 [==============================] - 5s 7ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0191 - cosine_proximity: 0.5370 - val_loss: 6.0841e-04 - val_mse: 6.0841e-04 - val_mae: 0.0154 - val_cosine_proximity: 0.5274\n",
      "Epoch 6/100\n",
      "792/792 [==============================] - 6s 7ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0193 - cosine_proximity: 0.5345 - val_loss: 6.5995e-04 - val_mse: 6.5995e-04 - val_mae: 0.0164 - val_cosine_proximity: 0.5274\n",
      "Epoch 7/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0194 - cosine_proximity: 0.5329 - val_loss: 6.7190e-04 - val_mse: 6.7190e-04 - val_mae: 0.0162 - val_cosine_proximity: 0.5274\n",
      "Epoch 8/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0194 - cosine_proximity: 0.5327 - val_loss: 6.5270e-04 - val_mse: 6.5270e-04 - val_mae: 0.0148 - val_cosine_proximity: 0.5274\n",
      "Epoch 9/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0191 - cosine_proximity: 0.5315 - val_loss: 5.8107e-04 - val_mse: 5.8107e-04 - val_mae: 0.0126 - val_cosine_proximity: 0.5274\n",
      "Epoch 10/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - cosine_proximity: 0.5314 - val_loss: 5.4341e-04 - val_mse: 5.4341e-04 - val_mae: 0.0124 - val_cosine_proximity: 0.5061\n",
      "Epoch 11/100\n",
      "792/792 [==============================] - 6s 7ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0183 - cosine_proximity: 0.5348 - val_loss: 5.4786e-04 - val_mse: 5.4786e-04 - val_mae: 0.0122 - val_cosine_proximity: 0.5151\n",
      "Epoch 12/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0181 - cosine_proximity: 0.5360 - val_loss: 5.1644e-04 - val_mse: 5.1644e-04 - val_mae: 0.0120 - val_cosine_proximity: 0.5075\n",
      "Epoch 13/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0204 - cosine_proximity: 0.5307 - val_loss: 5.3196e-04 - val_mse: 5.3196e-04 - val_mae: 0.0133 - val_cosine_proximity: 0.5274\n",
      "Epoch 14/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 9.6312e-04 - mse: 9.6312e-04 - mae: 0.0176 - cosine_proximity: 0.5324 - val_loss: 5.0424e-04 - val_mse: 5.0424e-04 - val_mae: 0.0120 - val_cosine_proximity: 0.5274\n",
      "Epoch 15/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 9.5053e-04 - mse: 9.5053e-04 - mae: 0.0172 - cosine_proximity: 0.5328 - val_loss: 5.0690e-04 - val_mse: 5.0690e-04 - val_mae: 0.0114 - val_cosine_proximity: 0.5274\n",
      "Epoch 16/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 9.4442e-04 - mse: 9.4442e-04 - mae: 0.0172 - cosine_proximity: 0.5315 - val_loss: 5.0601e-04 - val_mse: 5.0601e-04 - val_mae: 0.0114 - val_cosine_proximity: 0.5274\n",
      "Epoch 17/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 9.3392e-04 - mse: 9.3392e-04 - mae: 0.0171 - cosine_proximity: 0.5324 - val_loss: 5.0068e-04 - val_mse: 5.0068e-04 - val_mae: 0.0112 - val_cosine_proximity: 0.5274\n",
      "Epoch 18/100\n",
      "792/792 [==============================] - 6s 8ms/step - loss: 9.3342e-04 - mse: 9.3342e-04 - mae: 0.0171 - cosine_proximity: 0.5309 - val_loss: 4.9145e-04 - val_mse: 4.9145e-04 - val_mae: 0.0110 - val_cosine_proximity: 0.5274\n",
      "Epoch 19/100\n",
      "792/792 [==============================] - 7s 9ms/step - loss: 9.2591e-04 - mse: 9.2591e-04 - mae: 0.0170 - cosine_proximity: 0.5317 - val_loss: 4.8671e-04 - val_mse: 4.8671e-04 - val_mae: 0.0109 - val_cosine_proximity: 0.5274\n",
      "Epoch 20/100\n",
      "792/792 [==============================] - 10s 13ms/step - loss: 9.2024e-04 - mse: 9.2024e-04 - mae: 0.0170 - cosine_proximity: 0.5318 - val_loss: 4.8645e-04 - val_mse: 4.8645e-04 - val_mae: 0.0112 - val_cosine_proximity: 0.4924 - loss: 9.5931e-04 - mse: 9.5931e-04 - mae: 0.0\n",
      "Epoch 21/100\n",
      "792/792 [==============================] - 10s 12ms/step - loss: 82.4232 - mse: 82.4232 - mae: 0.7251 - cosine_proximity: 0.4385 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0647 - val_cosine_proximity: 0.3670\n",
      "Epoch 22/100\n",
      "792/792 [==============================] - 8s 10ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0698 - cosine_proximity: 0.4152 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0537 - val_cosine_proximity: 0.3980\n",
      "Epoch 23/100\n",
      "792/792 [==============================] - 7s 9ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0612 - cosine_proximity: 0.4359 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0407 - val_cosine_proximity: 0.4374\n",
      "Epoch 24/100\n",
      "792/792 [==============================] - 8s 10ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0524 - cosine_proximity: 0.4594 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0341 - val_cosine_proximity: 0.4425\n",
      "Epoch 25/100\n",
      "792/792 [==============================] - 7s 9ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0409 - cosine_proximity: 0.4828 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0296 - val_cosine_proximity: 0.4723\n",
      "Epoch 26/100\n",
      "792/792 [==============================] - 7s 9ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0385 - cosine_proximity: 0.4887 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0291 - val_cosine_proximity: 0.4696\n",
      "Epoch 27/100\n",
      "792/792 [==============================] - 7s 9ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0357 - cosine_proximity: 0.4958 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0227 - val_cosine_proximity: 0.4770\n",
      "Epoch 28/100\n",
      "792/792 [==============================] - 8s 10ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0302 - cosine_proximity: 0.5080 - val_loss: 5.7490e-04 - val_mse: 5.7490e-04 - val_mae: 0.0132 - val_cosine_proximity: 0.5164\n",
      "Epoch 29/100\n",
      "792/792 [==============================] - 9s 11ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0294 - cosine_proximity: 0.5072 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0290 - val_cosine_proximity: 0.4647\n",
      "Epoch 30/100\n",
      "792/792 [==============================] - 9s 12ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0287 - cosine_proximity: 0.5117 - val_loss: 6.3105e-04 - val_mse: 6.3105e-04 - val_mae: 0.0137 - val_cosine_proximity: 0.5254\n",
      "Epoch 31/100\n",
      "792/792 [==============================] - 8s 10ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0294 - cosine_proximity: 0.5135 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0263 - val_cosine_proximity: 0.5004\n",
      "Epoch 32/100\n",
      "792/792 [==============================] - 8s 10ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0279 - cosine_proximity: 0.5193 - val_loss: 8.5529e-04 - val_mse: 8.5529e-04 - val_mae: 0.0239 - val_cosine_proximity: 0.4704\n",
      "Epoch 33/100\n",
      "792/792 [==============================] - 8s 10ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0282 - cosine_proximity: 0.5186 - val_loss: 7.2295e-04 - val_mse: 7.2295e-04 - val_mae: 0.0212 - val_cosine_proximity: 0.4751\n",
      "Epoch 34/100\n",
      "792/792 [==============================] - 7s 9ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0270 - cosine_proximity: 0.5223 - val_loss: 7.0603e-04 - val_mse: 7.0603e-04 - val_mae: 0.0204 - val_cosine_proximity: 0.4686\n",
      "Epoch 35/100\n",
      "792/792 [==============================] - 7s 9ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0261 - cosine_proximity: 0.5241 - val_loss: 6.0541e-04 - val_mse: 6.0541e-04 - val_mae: 0.0168 - val_cosine_proximity: 0.4870\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = make_model(train_solar,val_solar,ga_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_feature, open('./LN2/Many_hyperpara_tuning/'+ 'best_feature.pkl','wb'))\n",
    "model.save('./LN2/Many_hyperpara_tuning/4H.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27870e2cba32afb35df83c15876cb6bec71e23ef70eb52b377eee57487520364"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
