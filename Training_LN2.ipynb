{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f09ec2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:43.374149Z",
     "start_time": "2023-03-09T09:07:39.480242Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import time\n",
    "xformatter = mdates.DateFormatter('%H:%M')  # for time axis plots\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('seaborn-whitegrid')\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from pickle import load,dump\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Bidirectional,BatchNormalization, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "from keras.backend import clear_session\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f2c5e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:43.390238Z",
     "start_time": "2023-03-09T09:07:43.375149Z"
    }
   },
   "outputs": [],
   "source": [
    "FORMAT_TIME='%Y-%m-%d %H:%M:%S'\n",
    "START_TIME_DAY = time(5,0,0)\n",
    "END_TIME_DAY = time(18,30,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fea0e49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:43.406056Z",
     "start_time": "2023-03-09T09:07:43.392153Z"
    }
   },
   "outputs": [],
   "source": [
    "TIME_1_STEP = 15 # minute\n",
    "step_lag_1_day = 24*60//TIME_1_STEP\n",
    "steps_2hours = 60*2//TIME_1_STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5535df91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:43.421494Z",
     "start_time": "2023-03-09T09:07:43.407964Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define optimization\n",
    "activation_list = ['linear','relu', 'tanh','sigmoid']\n",
    "optimizer_list = [Adam, RMSprop, SGD, Adamax]\n",
    "range_neurons = [8,100]\n",
    "selectors = []\n",
    "algorithm_param = {\n",
    "    'max_num_iteration': 5,\n",
    "    'population_size': 5,\n",
    "    'mutation_probability': 0.1,\n",
    "    'elit_ratio': 0.2,\n",
    "    'crossover_probability': 0.5,\n",
    "    'parents_portion': 0,\n",
    "    'crossover_type': 'uniform',\n",
    "    'max_iteration_without_improv': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed0ae8c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:43.436786Z",
     "start_time": "2023-03-09T09:07:43.423495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nhap du lieu train data\n",
    "def import_train_data(path_file_train):\n",
    "    df = pd.read_csv(path_file_train)\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp']\n",
    "                                      )\n",
    "    df = df.set_index('TimeStamp')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "021de00e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:43.452247Z",
     "start_time": "2023-03-09T09:07:43.437698Z"
    }
   },
   "outputs": [],
   "source": [
    "def resample_df(df, resample_time, time_col='TimeStamp'):\n",
    "    \"\"\"\n",
    "    resample_time: `minute`\n",
    "    \"\"\"\n",
    "    resample_df = df.copy()\n",
    "    if resample_time >= 30:\n",
    "        resample_df = resample_df.set_index(\n",
    "            resample_df[time_col] - to_offset(str(resample_time//2)+\"min\"))\n",
    "    resample_df = resample_df.resample(str(resample_time)+'min', label='right').mean()\n",
    "    return resample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d79ce8ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:54.881046Z",
     "start_time": "2023-03-09T09:07:43.453249Z"
    }
   },
   "outputs": [],
   "source": [
    "all_plant = import_train_data('./LN2_training.csv')\n",
    "# all_plant = all_plant.reset_index()\n",
    "all_plant = resample_df(all_plant, resample_time = 15, time_col='TimeStamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85adf214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:54.912643Z",
     "start_time": "2023-03-09T09:07:54.883093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotW</th>\n",
       "      <th>I_GHI</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeStamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-01 00:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.258230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.100050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01 00:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.941867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.783687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01 01:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.658317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.619470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31 23:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.582193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31 23:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.544917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31 23:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.507643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.470367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49728 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TotW  I_GHI          T\n",
       "TimeStamp                                  \n",
       "2021-04-01 00:15:00   0.0    0.0  28.258230\n",
       "2021-04-01 00:30:00   0.0    0.0  28.100050\n",
       "2021-04-01 00:45:00   0.0    0.0  27.941867\n",
       "2021-04-01 01:00:00   0.0    0.0  27.783687\n",
       "2021-04-01 01:15:00   0.0    0.0  27.658317\n",
       "...                   ...    ...        ...\n",
       "2022-08-31 23:00:00   0.0    0.0  25.619470\n",
       "2022-08-31 23:15:00   0.0    0.0  25.582193\n",
       "2022-08-31 23:30:00   0.0    0.0  25.544917\n",
       "2022-08-31 23:45:00   0.0    0.0  25.507643\n",
       "2022-09-01 00:00:00   0.0    0.0  25.470367\n",
       "\n",
       "[49728 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea47dd4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:54.927966Z",
     "start_time": "2023-03-09T09:07:54.917565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split train, val data theo ti le 8/2\n",
    "def train_valid_split(df, split_ratio=[0.8, 0.2]):\n",
    "    train_ratio, valid_ratio = split_ratio\n",
    "    assert train_ratio + valid_ratio  == 1.0\n",
    "    n_df = len(df)\n",
    "    # Train / Validation  Split\n",
    "    train_split = int(n_df * train_ratio)\n",
    "    valid_split = int(n_df * (train_ratio + valid_ratio))\n",
    "\n",
    "    train = df[:train_split]\n",
    "    val = df[train_split:valid_split]\n",
    "\n",
    "    print(f'Train set: {len(train)} ')\n",
    "    print(f'Validation set: {len(val)} ')\n",
    "\n",
    "    return train, val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56859181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:54.943364Z",
     "start_time": "2023-03-09T09:07:54.928967Z"
    }
   },
   "outputs": [],
   "source": [
    "def num_step_1hour(df):\n",
    "    \"\"\"\n",
    "    Get number step of 1 hours\n",
    "    \"\"\"\n",
    "    step_hours = None\n",
    "    if type(df.index) == pd.core.indexes.datetimes.DatetimeIndex:\n",
    "        time_1step = int((df.index[1] - df.index[0]) /\n",
    "                         np.timedelta64(1, 'm'))  # minute\n",
    "        step_hours = 60 // time_1step\n",
    "    return step_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1abe5bb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:54.958918Z",
     "start_time": "2023-03-09T09:07:54.944457Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_data_supervised(dt, num_pre_around=5, num_day_pre=3):\n",
    "    step_lag_1_day = num_step_1hour(dt)*24\n",
    "    dt_lag = pd.DataFrame()\n",
    "    for col in dt.columns:\n",
    "        for day_pre in range(num_pre_around+1):\n",
    "            if day_pre == 0:\n",
    "                dt_lag[col+'(t)'] = dt[col]\n",
    "            else:\n",
    "                dt_lag[col+'(t-'+str(day_pre)+')'] = dt[col].shift(day_pre)\n",
    "        for day_pre in range(1, num_day_pre):\n",
    "            step_lag = step_lag_1_day*day_pre\n",
    "            for lag in range(num_pre_around+1):\n",
    "                dt_lag[col+'(t-'+str(step_lag+lag) +\n",
    "                       ')'] = dt[col].shift(step_lag+lag)\n",
    "                dt_lag[col+'(t-'+str(step_lag-lag) +\n",
    "                       ')'] = dt[col].shift(step_lag-lag)\n",
    "    dt_lag = dt_lag.dropna()\n",
    "    dt_lag['hour'] = dt_lag.index.hour\n",
    "    dt_lag['day'] = dt_lag.index.day\n",
    "    dt_lag['day_of_week'] = dt_lag.index.dayofweek\n",
    "    dt_lag['month'] = dt_lag.index.month\n",
    "    dt_lag['day_of_year'] = dt_lag.index.dayofyear\n",
    "    return dt_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b0b8bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:54.975029Z",
     "start_time": "2023-03-09T09:07:54.960919Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_Kbest(train,score_f):\n",
    "    X_select = train[train.columns[1:]]\n",
    "    y_select = train['TotW(t)']\n",
    "    bestfeatures = SelectKBest(score_func=score_f, k='all')\n",
    "    fit = bestfeatures.fit(X_select,y_select)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X_select.columns)\n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  \n",
    "    featureScores = featureScores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "    return featureScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59b8ec56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:54.990042Z",
     "start_time": "2023-03-09T09:07:54.976042Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_model(train, val, ga_result):\n",
    "    train_X, train_y = train.values[:, 1:], train.values[:, :1]\n",
    "    train_X = train_X.reshape(train_X.shape[0], 1, train_X.shape[1])\n",
    "\n",
    "    val_X, val_y = val.values[:, 1:], val.values[:, :1]\n",
    "    val_X = val_X.reshape(val_X.shape[0], 1, val_X.shape[1])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Bidirectional(LSTM(ga_result['num_feature'],\n",
    "             activation=ga_result['activations'],\n",
    "             input_shape=(train_X.shape[1], train_X.shape[2])),merge_mode= 'ave'))\n",
    "    \n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))   \n",
    "    # model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer=ga_result['optimizers'](learning_rate = 0.001),\n",
    "                  metrics=['mse', 'mae', 'cosine_proximity'])\n",
    "    # fit network\n",
    "    history = model.fit(train_X,\n",
    "                        train_y,\n",
    "                        epochs=100,\n",
    "                        batch_size=50,\n",
    "                        validation_data=(val_X, val_y),\n",
    "                        verbose=1,\n",
    "                        shuffle=False,\n",
    "                        callbacks=EarlyStopping(monitor='val_loss',\n",
    "                                                patience=15,\n",
    "                                                restore_best_weights=True))\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    fig.suptitle('Loss', y=0.93)\n",
    "    ax.plot(history.history['mae'], label='train')\n",
    "    ax.plot(history.history['val_mae'], label='val')\n",
    "    ax.set_title('mae')\n",
    "    ax.legend(loc='upper right')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8851983b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:55.005266Z",
     "start_time": "2023-03-09T09:07:54.992036Z"
    }
   },
   "outputs": [],
   "source": [
    "def GA_result(ga_model):\n",
    "    best_neurons = (int(ga_model.best_variable[0]))\n",
    "    best_activation = (int(ga_model.best_variable[1]))\n",
    "    best_optimizer = (int(ga_model.best_variable[2]))\n",
    "    return {\n",
    "        'activations': activation_list[best_activation],\n",
    "        'optimizers': optimizer_list[best_optimizer],\n",
    "        'neurons': best_neurons,\n",
    "        'num_feature': int(ga_model.best_variable[3])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c66d86f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:55.021300Z",
     "start_time": "2023-03-09T09:07:55.006194Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_or_create_path(path):\n",
    "    if os.path.isdir(path) is False:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45f362fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:55.036483Z",
     "start_time": "2023-03-09T09:07:55.023291Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_func(train, val, path_scale):\n",
    "    get_or_create_path(path_scale)\n",
    "    train_scale_df = pd.DataFrame(index=train.index)\n",
    "    val_scale_df = pd.DataFrame(index=val.index)\n",
    "    \n",
    "    for col in train.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        train_scale_df[col] = scaler.fit_transform(train[col].values.reshape(-1,1))[:,0]\n",
    "        val_scale_df[col] = scaler.transform(val[col].values.reshape(-1,1))[:,0]\n",
    "        pickle.dump(scaler, open(path_scale + col+'.pkl','ab+'))\n",
    "    return train_scale_df,val_scale_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "630007b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T09:07:55.068082Z",
     "start_time": "2023-03-09T09:07:55.038515Z"
    }
   },
   "outputs": [],
   "source": [
    "#def tong\n",
    "def LSTM_generetic(df, path_model, path_scale, path_feature):\n",
    "    #HÃ m evaluate\n",
    "    def evaluate(gene):\n",
    "        g = [int(i) for i in gene]\n",
    "        train_X_ = train_X.copy()\n",
    "        val_X_ = val_X.copy()\n",
    "        train_y_ = train_y.copy()\n",
    "        val_y_ = val_y.copy()\n",
    "        selector = SelectKBest(score_func=f_regression, k=g[3])\n",
    "        train_X_ = train_X_.reshape(train_X_.shape[0], train_X_.shape[2])\n",
    "        val_X_ = val_X_.reshape(val_X_.shape[0], val_X_.shape[2])\n",
    "        train_X_ = selector.fit_transform(train_X_, train_y_)\n",
    "        val_X_ = selector.transform(val_X_)\n",
    "        train_X_ = train_X_.reshape(train_X_.shape[0],1,train_X_.shape[1])\n",
    "        val_X_ = val_X_.reshape(val_X_.shape[0],1,val_X_.shape[1])\n",
    "        neurons = g[0]\n",
    "        activation = activation_list[g[1]]\n",
    "        optimizer = optimizer_list[g[2]] \n",
    "        print('\\nNumber of neurons: ', neurons,\n",
    "              ', activation function: ', activation,\n",
    "              ', optimizer function: ', optimizer,\n",
    "              ', features: ', g[3])\n",
    "        clear_session()\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(neurons, activation=activation, \n",
    "                                     input_shape=(train_X_.shape[1], train_X_.shape[2]),return_sequences=True)))\n",
    "        model.add(LSTM(64))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(Dropout(0.2))   \n",
    "        # model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mae', optimizer=optimizer(learning_rate = 0.001))\n",
    "        history = model.fit(train_X_, train_y_,validation_data=(val_X_, val_y_),callbacks = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True), \n",
    "            epochs=100, batch_size=50, verbose=0,shuffle=False)\n",
    "        print('val_loss: ', min(history.history['val_loss']))\n",
    "        return min(history.history['val_loss'])\n",
    "        \n",
    "    \n",
    "    train_solar, val_solar = train_valid_split(df,split_ratio=[0.8, 0.2]) # split train/val\n",
    "    train_scale, val_scale = scale_func(train_solar, val_solar, path_scale)\n",
    "\n",
    "    train_scaler_lag = make_data_supervised(train_scale)\n",
    "    val_scaler_lag = make_data_supervised(val_scale)\n",
    "    \n",
    "    col_analysis = list(train_scaler_lag)\n",
    "    train_solar = train_scaler_lag[col_analysis].copy()\n",
    "    val_solar = val_scaler_lag[col_analysis].copy()\n",
    "    \n",
    "    featureScores = select_Kbest(train_solar[col_analysis],f_regression)\n",
    "    featureScores.to_csv('./LN2_4H_kbest.csv')\n",
    "    \n",
    "    train_X, train_y= train_solar.values[:, 1:],train_solar.values[:, :1]\n",
    "    train_X = train_X.reshape(train_X.shape[0], 1, train_X.shape[1])\n",
    "    val_X, val_y= val_solar.values[:, 1:],val_solar.values[:, :1]\n",
    "    val_X = val_X.reshape(val_X.shape[0], 1, val_X.shape[1])\n",
    "    \n",
    "    best_activation, best_optimizer, best_neurons, selectors = [], [], [], []\n",
    "    varbound = np.array([range_neurons, [0, 3], [0, 3], [1, train_X.shape[2]]])\n",
    "    ga_model = ga(function=evaluate,\n",
    "                dimension=4,\n",
    "                variable_type='int',\n",
    "                function_timeout=10000,\n",
    "                variable_boundaries=varbound,\n",
    "                convergence_curve=False,\n",
    "                algorithm_parameters=algorithm_param)\n",
    "    ga_model.run()\n",
    "    \n",
    "    ga_result = GA_result(ga_model)\n",
    "    best_feature = list(featureScores['Specs'][:ga_result['num_feature']])\n",
    "    pickle.dump(best_feature, open(path_feature + 'best_feature.pkl','wb'))\n",
    "    train_solar = train_scaler_lag[['TotW(t)']+best_feature]\n",
    "    val_solar = val_scaler_lag[['TotW(t)']+best_feature]\n",
    "     \n",
    "    model = make_model(train_solar,val_solar,ga_result)\n",
    "    model.save(path_model)\n",
    "    \n",
    "    return featureScores, ga_result, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e182272",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-09T09:07:39.491Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 39782 \n",
      "Validation set: 9946 \n",
      "\n",
      "Number of neurons:  40 , activation function:  sigmoid , optimizer function:  <class 'keras.optimizer_v2.adamax.Adamax'> , features:  30\n",
      "val_loss:  0.010581242851912975\n",
      "\n",
      "Number of neurons:  22 , activation function:  tanh , optimizer function:  <class 'keras.optimizer_v2.gradient_descent.SGD'> , features:  53\n",
      "val_loss:  0.03555513918399811\n",
      "\n",
      "Number of neurons:  47 , activation function:  sigmoid , optimizer function:  <class 'keras.optimizer_v2.adamax.Adamax'> , features:  5\n",
      "val_loss:  0.01090223528444767\n",
      "\n",
      "Number of neurons:  66 , activation function:  sigmoid , optimizer function:  <class 'keras.optimizer_v2.gradient_descent.SGD'> , features:  26\n",
      "val_loss:  0.04634219408035278\n",
      "\n",
      "Number of neurons:  39 , activation function:  tanh , optimizer function:  <class 'keras.optimizer_v2.adam.Adam'> , features:  51\n",
      "val_loss:  0.010760901495814323\n",
      "||||||||||________________________________________ 20.0% GA is running...\n",
      "Number of neurons:  40 , activation function:  sigmoid , optimizer function:  <class 'keras.optimizer_v2.gradient_descent.SGD'> , features:  30\n",
      "val_loss:  0.04455764964222908\n",
      "\n",
      "Number of neurons:  40 , activation function:  sigmoid , optimizer function:  <class 'keras.optimizer_v2.adamax.Adamax'> , features:  43\n"
     ]
    }
   ],
   "source": [
    "LSTM_generetic(all_plant,'./LN2/4H.h5','./LN2/','./LN2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843954a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
